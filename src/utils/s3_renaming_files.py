import boto3

s3 = boto3.client("s3")

def move_and_rename_parquet_file(bucket: str, tmp_prefix: str, final_key: str):
    """
    Moves and renames a single .parquet file generated by Spark (via coalesce(1)) 
    from a temporary S3 folder to a final destination key.

    It also deletes all temporary files after the move to keep S3 clean.

    Args:
        bucket (str): Name of the S3 bucket (e.g., "case-bees").
        tmp_prefix (str): Temporary S3 prefix where Spark saved the file 
                          (e.g., "tmp/gold/breweries_agg/").
        final_key (str): Final S3 key with the desired file name 
                         (e.g., "gold/breweries_by_type_and_country.parquet").

    Raises:
        FileNotFoundError: If no .parquet file is found under the temporary prefix.
    """

    # List all objects in the temporary S3 folder
    response = s3.list_objects_v2(Bucket=bucket, Prefix=tmp_prefix)

    parquet_key = None
    # Look for the first .parquet file inside the temporary folder
    for obj in response.get("Contents", []):
        key = obj["Key"]
        if key.endswith(".parquet"):
            parquet_key = key
            break

    if parquet_key is None:
        raise FileNotFoundError(f"No .parquet file found in {tmp_prefix}")

    # Copy the parquet file to the final destination with the desired name
    s3.copy_object(
        Bucket=bucket,
        CopySource={'Bucket': bucket, 'Key': parquet_key},
        Key=final_key
    )

    # Delete all temporary files (including _SUCCESS and part files)
    for obj in response.get("Contents", []):
        s3.delete_object(Bucket=bucket, Key=obj["Key"])
